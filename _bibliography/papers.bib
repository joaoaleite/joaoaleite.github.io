---
---
@inproceedings{leite-etal-2020-toxic,
    abbr = {AACL},
    title = "Toxic Language Detection in Social Media for {B}razilian {P}ortuguese: New Dataset and Multilingual Analysis",
    author = "Leite, Jo{\~a}o A.  and
      Silva, Diego  and
      Bontcheva, Kalina  and
      Scarton, Carolina",
    editor = "Wong, Kam-Fai  and
      Knight, Kevin  and
      Wu, Hua",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.91",
    html = {https://aclanthology.org/2020.aacl-main.91},
    pages = "914--924",
    abstract = "Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76{\%} macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.",
    selected = {true},
    google_scholar_id = {u-x6o8ySG0sC},
    pdf = {toxic_2020.pdf},
    dimensions = {true},
}


@article{leite2024weaklysupervisedveracityclassification,
  abbr = {EPJ Data Science},
  title={Weakly supervised veracity classification with LLM-predicted credibility signals},
  author={Leite, Jo{\~a}o A and Razuvayevskaya, Olesya and Bontcheva, Kalina and Scarton, Carolina},
  journal={EPJ Data Science},
  volume={14},
  number={1},
  pages={16},
  year={2025},
  month={02},
  publisher={Springer Berlin Heidelberg},
  selected = {true},
  google_scholar_id = {Tyk-4Ss8FVUC},
  pdf = {pastel.pdf},
  html = {https://epjds.epj.org/articles/epjdata/abs/2025/01/13688_2025_Article_534/13688_2025_Article_534.html},
  url = {https://epjds.epj.org/articles/epjdata/abs/2025/01/13688_2025_Article_534/13688_2025_Article_534.html}
}

@inproceedings{10.1145/3627673.3679167,
abbr = {CIKM},
author = {Leite, Jo\~{a}o A. and Razuvayevskaya, Olesya and Bontcheva, Kalina and Scarton, Carolina},
title = {EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679167},
doi = {10.1145/3627673.3679167},
abstract = {This work introduces EUvsDisinfo, a multilingual dataset of disinformation articles originating from pro-Kremlin outlets, along with trustworthy articles from credible / less biased sources. It is sourced directly from the debunk articles written by experts leading the EUvsDisinfo project. Our dataset is the largest to-date resource in terms of the overall number of articles and distinct languages. It also provides the largest topical and temporal coverage. Using this dataset, we investigate the dissemination of pro-Kremlin disinformation across different languages, uncovering language-specific patterns targeting certain disinformation topics. We further analyse the evolution of topic distribution over an eight-year period, noting a significant surge in disinformation content before the full-scale invasion of Ukraine in 2022. Lastly, we demonstrate the dataset's applicability in training models to effectively distinguish between disinformation and trustworthy content in multilingual settings.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5380–5384},
numpages = {5},
keywords = {classification, dataset, disinformation, news articles, pro-kremlin},
location = {Boise, ID, USA},
series = {CIKM '24},
selected = {true},
google_scholar_id = {YsMSGLbcyi4C},
pdf = {euvsdisinfo_cikm.pdf},
}

@inproceedings{leite2024cross,
  abbr = {WWW},
  author = {Leite, Jo\~{a}o A. and Razuvayevskaya, Olesya and Scarton, Carolina and Bontcheva, Kalina},
  title = {A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation},
  year = {2024},
  month= {12},
  isbn = {9798400713316},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3701716.3715535},
  doi = {10.1145/3701716.3715535},
  abstract = {Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation narratives, however, has been mostly limited to specific topics (e.g., COVID-19).To address this gap, our study conducts a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives, by leveraging a state-of-the-art persuasion technique classifier. We demonstrate how different persuasion techniques are employed disproportionately in different disinformation domains. We also include an in-depth case study on climate change disinformation, which demonstrates how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.},
  booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
  pages = {1100–1103},
  numpages = {4},
  keywords = {disinformation, domain adaptation, persuasion techniques},
  location = {Sydney NSW, Australia},
  series = {WWW '25},
  selected = {true},
  google_scholar_id = {Se3iqnhoufwC},
  pdf = {www2024.pdf}
}

@article{olesya-2024-comparison,
    abbr = {PLOS ONE},
    doi = {10.1371/journal.pone.0301738},
    author = {Razuvayevskaya, Olesya AND Wu, Ben AND Leite, João A. AND Heppell, Freddy AND Srba, Ivan AND Scarton, Carolina AND Bontcheva, Kalina AND Song, Xingyi},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Comparison between parameter-efficient techniques and full fine-tuning: A case study on multilingual news article classification},
    year = {2024},
    month = {05},
    volume = {19},
    url = {https://doi.org/10.1371/journal.pone.0301738},
    pages = {1-26},
    abstract = {Adapters and Low-Rank Adaptation (LoRA) are parameter-efficient fine-tuning techniques designed to make the training of language models more efficient. Previous results demonstrated that these methods can even improve performance on some classification tasks. This paper complements existing research by investigating how these techniques influence classification performance and computation costs compared to full fine-tuning. We focus specifically on multilingual text classification tasks (genre, framing, and persuasion techniques detection; with different input lengths, number of predicted classes and classification difficulty), some of which have limited training data. In addition, we conduct in-depth analyses of their efficacy across different training scenarios (training on the original multilingual data; on the translations into English; and on a subset of English-only data) and different languages. Our findings provide valuable insights into the applicability of parameter-efficient fine-tuning techniques, particularly for multilabel classification and non-parallel multilingual tasks which are aimed at analysing input texts of varying length.},
    number = {5},
    selected = {false},
    google_scholar_id = {zYLM7Y9cAGgC},
    pdf = {comparison-plos.pdf},
}

@article{srba2024survey,
  title={A Survey on Automatic Credibility Assessment of Textual Credibility Signals in the Era of Large Language Models},
  author={Srba, Ivan and Razuvayevskaya, Olesya and Leite, Jo{\~a}o A and Moro, Robert and Schlicht, Ipek Baris and Tonelli, Sara and Garc{\'\i}a, Francisco Moreno and Lottmann, Santiago Barrio and Teyssou, Denis and Porcellini, Valentin and others},
  year={2024},
  month={10},
  abbr = {arXiv},
  archivePrefix={arXiv},
  eprint={2410.21360},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.21360},
  selected = {false},
  google_scholar_id = {roLk4NBRz8UC},
}

@inproceedings{wu-etal-2023-sheffieldveraai,
    abbr = {ACL-SemEval},
    title = "SheffieldVeraAI at SemEval-2023 Task 3: Mono and Multilingual Approaches for News Genre, Topic and Persuasion Technique Classification",
    author = "Wu, Ben  and
      Razuvayevskaya, Olesya  and
      Heppell, Freddy  and
      Leite, Jo{\~a}o A.  and
      Scarton, Carolina  and
      Bontcheva, Kalina  and
      Song, Xingyi",
    editor = {Ojha, Atul Kr.  and
      Do{\u{g}}ru{\"o}z, A. Seza  and
      Da San Martino, Giovanni  and
      Tayyar Madabushi, Harish  and
      Kumar, Ritesh  and
      Sartori, Elisa},
    booktitle = "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.semeval-1.275/",
    doi = "10.18653/v1/2023.semeval-1.275",
    pages = "1995--2008",
    abstract = "This paper describes our approach for SemEval- 2023 Task 3: Detecting the category, the fram- ing, and the persuasion techniques in online news in a multilingual setup. For Subtask 1 (News Genre), we propose an ensemble of fully trained and adapter mBERT models which was ranked joint-first for German, and had the high- est mean rank of multi-language teams. For Subtask 2 (Framing), we achieved first place in 3 languages, and the best average rank across all the languages, by using two separate ensem- bles: a monolingual RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task adaptive pretraining. For Sub- task 3 (Persuasion Techniques), we trained a monolingual RoBERTa-Base model for English and a multilingual mBERT model for the re- maining languages, which achieved top 10 for all languages, including 2nd for English. For each subtask, we compared monolingual and multilingual approaches, and considered class imbalance techniques.",
    google_scholar_id = {UeHWp8X0CEIC},
    pdf = {persuasion-semeval.pdf},
}

@inproceedings{leite-etal-2023-noisy,
    abbr = {RANLP},
    title = "Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks",
    author = "Leite, Jo{\~a}o  and
      Scarton, Carolina  and
      Silva, Diego",
    editor = "Mitkov, Ruslan  and
      Angelova, Galia",
    booktitle = "Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing",
    month = sep,
    year = "2023",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd., Shoumen, Bulgaria",
    url = "https://aclanthology.org/2023.ranlp-1.68/",
    pages = "631--640",
    abstract = "Online social media is rife with offensive and hateful comments, prompting the need for their automatic detection given the sheer amount of posts created every second. Creating high-quality human-labelled datasets for this task is difficult and costly, especially because non-offensive posts are significantly more frequent than offensive ones. However, unlabelled data is abundant, easier, and cheaper to obtain. In this scenario, self-training methods, using weakly-labelled examples to increase the amount of training data, can be employed. Recent {\textquotedblleft}noisy{\textquotedblright} self-training approaches incorporate data augmentation techniques to ensure prediction consistency and increase robustness against noisy data and adversarial attacks. In this paper, we experiment with default and noisy self-training using three different textual data augmentation techniques across five different pre-trained BERT architectures varying in size. We evaluate our experiments on two offensive/hate-speech datasets and demonstrate that (i) self-training consistently improves performance regardless of model size, resulting in up to +1.5{\%} F1-macro on both datasets, and (ii) noisy self-training with textual data augmentations, despite being successfully applied in similar settings, decreases performance on offensive and hate-speech domains when compared to the default method, even with state-of-the-art augmentations such as backtranslation.",
    selected = {true},
    google_scholar_id = {W7OEmFMy1HYC},
    pdf = {noisy-self-training-ranlp.pdf},
}