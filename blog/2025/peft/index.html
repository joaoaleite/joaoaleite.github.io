<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Parameter-Efficient Fine-Tuning with LoRA | João A. Leite </title> <meta name="author" content="João A. Leite"> <meta name="description" content=""> <meta name="keywords" content="AI, Machine Learning, Natural Language Processing"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A5%9B&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joaoaleite.github.io/blog/2025/peft/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Parameter-Efficient Fine-Tuning with LoRA",
            "description": "",
            "published": "August 16, 2025",
            "authors": [
              
              {
                "author": "João Leite",
                "authorURL": "https://jaleite.com",
                "affiliations": [
                  {
                    "name": "University of Sheffield",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">João</span> A. Leite </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav"> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/resume.pdf" target="_blank">resume</a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Parameter-Efficient Fine-Tuning with LoRA</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <ul> <li> <a href="#motivation">Motivation</a> </li> <li> <a href="#peft-strategies">PEFT Strategies</a> </li> </ul> <div> <a href="#low-rank-adaptation-lora">Low-Rank Adaptation (LoRA)</a> </div> <ul> <li> <a href="#the-core-mechanism">The Core Mechanism</a> </li> <li> <a href="#key-advantages">Key Advantages</a> </li> <li> <a href="#lora-in-the-transformer-architecture">LoRA in the Transformer Architecture</a> </li> </ul> <div> <a href="#implementation">Implementation</a> </div> <ul> <li> <a href="#applying-lora-to-an-existing-model">Applying LoRA to an Existing Model</a> </li> </ul> </nav> </d-contents> <h1 id="introduction">Introduction</h1> <p>Modern Large Language Models (LLMs) are powerful general-purpose tools that need to be trained in multiple stages involving different methodologies. For the purpose of this post, we will discuss two of them.</p> <p>The first is the foundational <strong>pre-training</strong> stage, where the model is trained from scratch on a massive, diverse corpus of text. The objective is purely self-supervised learning, and the model typically learns to predict the next token in a given sentence. This step is computationally intensive, and its objective is to allow the model to learn general representations of language. At the end of this stage, the model is a powerful generalist but is not specialized for any specific task.</p> <p>The second stage is <strong>fine-tuning</strong>, where the base model is trained using a much smaller, curated dataset for a specific task (e.g., becoming an assistant that follows instructions). The goal is to adapt the model for this task without it losing the general knowledge acquired during pre-training.</p> <p>In this context, <strong>Parameter-Efficient Fine-Tuning (PEFT)</strong>, as the name suggests, is a family of methods that allow us to perform the fine-tuning step in a more efficient and controlled manner.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogposts/2025-08-16-peft/pretraining-and-finetuning-480.webp 480w,/assets/img/blogposts/2025-08-16-peft/pretraining-and-finetuning-800.webp 800w,/assets/img/blogposts/2025-08-16-peft/pretraining-and-finetuning-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blogposts/2025-08-16-peft/pretraining-and-finetuning.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 1.</b> Pre-training and fine-tuning (<a href="https://medium.com/@eordaxd/fine-tuning-vs-pre-training-651d05186faf" rel="external nofollow noopener" target="_blank">Source</a>). </div> <h2 id="motivation">Motivation</h2> <p>The most straightforward method to adapt a pre-trained model is to continue the training process, updating every single weight using a new, task-specific dataset. This approach is known as <strong>full fine-tuning (FFT)</strong>.</p> <p>However, full fine-tuning presents several significant drawbacks. First, by directly modifying all pre-trained weights, it risks erasing the valuable general-purpose knowledge they contain, a phenomenon known as <strong>catastrophic forgetting</strong>.</p> <p>Second, updating the entire model is computationally expensive. It requires a large amount of GPU memory to store not only the gradients for every parameter but also the memory-intensive states required by optimizers like AdamW. For a 7-billion-parameter model, this can easily exceed <strong>80 GB of VRAM</strong>.</p> <p>Another challenge is storage and deployment. Full fine-tuning requires creating and storing a complete, independent copy of the model for each task. Fine-tuning a 7B model for five different tasks would mean storing five separate 14 GB models, totaling 70 GB.</p> <h2 id="peft-strategies">PEFT Strategies</h2> <p>The core idea behind all PEFT methods is to <strong>freeze the vast majority of the pre-trained model’s parameters and only update a small, targeted subset</strong> (often less than 1%). This drastically reduces the memory and compute required for training and mitigates catastrophic forgetting.</p> <p>There are several families of PEFT methods:</p> <ul> <li> <strong>Additive (e.g., Adapters)</strong>: These methods add new trainable layers or modules into the Transformer architecture while keeping the original weights frozen.</li> <li> <strong>Selective (e.g., BitFit)</strong>: These methods unfreeze and update only a small subset of the original model’s parameters, such as the bias terms.</li> <li> <strong>Reparameterization (e.g., LoRA)</strong>: These methods reparameterize the weight update as a smaller, more efficient transformation.</li> </ul> <p>This post will focus on <strong>Low-Rank Adaptation (LoRA)</strong>, which has become the most dominant and widely-used PEFT method due to its unique combination of performance and efficiency.</p> <h1 id="low-rank-adaptation-lora">Low-Rank Adaptation (LoRA)</h1> <p>LoRA (Hu, Edward J., et al <d-cite key="hu2021loralowrankadaptationlarge"></d-cite>) is a PEFT method based on the insight that the <em>change</em> in a model’s weights during fine-tuning ($\Delta W$) has a very low “intrinsic rank.” In other words, the updates to the weight matrices can be efficiently approximated by much simpler, low-rank matrices.</p> <blockquote> <p><strong>Reminder:</strong> The <strong>rank</strong> of a matrix is the number of linearly independent columns (or rows) it has. Intuitively, it measures the “dimensionality” of the information the matrix contains. A low-rank matrix is one where this information is highly redundant.</p> </blockquote> <h3 id="the-core-mechanism">The Core Mechanism</h3> <p>Instead of updating the original pre-trained weight matrix $W$, LoRA represents the update $\Delta W$ as the product of two much smaller matrices, $A$ (the “down-projection”) and $B$ (the “up-projection”):</p> \[\Delta W \approx A \cdot B\] <p>Where if the original weight matrix $W$ has dimensions $d \times k$, the new matrices will have dimensions $A$ ($d \times r$) and $B$ ($r \times k$). The hyperparameter <code class="language-plaintext highlighter-rouge">r</code> is the rank of the decomposition, and it is much smaller than $d$ or $k$. This leads to a massive reduction in trainable parameters.</p> <blockquote> <p>For a typical 4096x4096 attention matrix (~16.7M params), using LoRA with a rank of $r=8$ requires training only two matrices 4096x8 and 8x4096, totaling ~65k parameters. This represents a <strong>reduction of over 99.6%</strong>.</p> </blockquote> <p>During the forward pass, the model’s output is calculated by adding the output of the frozen pre-trained layer to the output of the new LoRA path:</p> \[y=Wx + BAx = (W + BA)x\] <div class="row mt-3" style="max-width: 50%; height: auto; margin: 0 auto;"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogposts/2025-08-16-peft/lora_inference-480.webp 480w,/assets/img/blogposts/2025-08-16-peft/lora_inference-800.webp 800w,/assets/img/blogposts/2025-08-16-peft/lora_inference-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blogposts/2025-08-16-peft/lora_inference.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 3.</b> LoRA: The input $x$ flows through the frozen layer $W$ and two smaller matrices $A$ and $B$.<br> (Source: Hu, Edward J., et al <d-cite key="hu2021loralowrankadaptationlarge"></d-cite>). </div> <h3 id="key-advantages">Key Advantages</h3> <p>LoRA has become the default PEFT method due to its unique combination of efficiency and performance, offering key advantages over other strategies:</p> <ul> <li> <strong>No Inference Latency:</strong> Unlike <strong>Adapters</strong>, which add new layers into the model, LoRA’s learned matrices can be merged back into the original weights after training. This means it introduces <strong>zero computational overhead</strong> during inference, which is critical for production environments.</li> <li> <strong>High Expressiveness:</strong> Compared to <strong>BitFit</strong>, which only fine-tunes bias terms, LoRA’s low-rank update matrices have more expressive capacity, allowing the model to learn more complex adaptations while still being highly parameter-efficient.</li> </ul> <h3 id="lora-in-the-transformer-architecture">LoRA in the Transformer Architecture</h3> <p>LoRA is strategically applied to layers where adaptation is most effective. The most common targets are the linear projection matrices within the <strong>multi-head attention (MHA)</strong> block, specifically the <strong>Query ($W_Q$)</strong> and <strong>Value ($W_V$)</strong> matrices. Adapting how the model queries for and extracts information is a highly efficient way to specialize it for a new task. For more complex adaptations, LoRA can also be applied to the other attention projections ($W_K, W_O$) and the layers of the feed-forward network (FFN).</p> <h2 id="implementation">Implementation</h2> <p>The LoRA matrix $A$ is typically initialized with random Gaussian values (e.g., Kaiming initialization), while $B$ is initialized to all <strong>zeros</strong>. This ensures the update is zero at the start of training. An additional hyperparameter $\alpha$ scales the update, allowing control over the adaptation strength independently of the rank <code class="language-plaintext highlighter-rouge">r</code>. The forward pass becomes:</p> \[y=Wx+\frac{\alpha}{r}BAx\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LoRALayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        
        <span class="n">device</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">device</span>
        <span class="n">d</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">out_features</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">kaiming_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">lora_A</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

        <span class="n">self</span><span class="p">.</span><span class="n">merged</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="n">frozen_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nc">W</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">lora_update</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">frozen_out</span> <span class="o">+</span> <span class="n">lora_update</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nc">W</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="n">update</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">update</span><span class="p">.</span><span class="n">T</span>
            <span class="n">self</span><span class="p">.</span><span class="n">merged</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">unmerge</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="n">update</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">update</span><span class="p">.</span><span class="n">T</span>
            <span class="n">self</span><span class="p">.</span><span class="n">merged</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div> <h3 id="applying-lora-to-an-existing-model">Applying LoRA to an Existing Model</h3> <p>To integrate LoRA into an existing PyTorch model without having to modify its implementation, we can write helper functions that handle the process of replacing existing linear layers with LoRA layers, and then after fine-tuning, re-inserting the original layers now with the updated weights. Our strategy is to dynamically modify the pre-trained model in-place.</p> <p>The <code class="language-plaintext highlighter-rouge">get_lora_model</code> function prepares a standard Transformer for LoRA fine-tuning. It iterates through the model, freezes all of its original parameters, and replaces the target <code class="language-plaintext highlighter-rouge">nn.Linear</code> layers with our custom <code class="language-plaintext highlighter-rouge">LoRALayer</code> modules. Finally, it unfreezes only the newly added <code class="language-plaintext highlighter-rouge">lora_</code> parameters, ensuring that the optimizer will only update the adapter weights.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_lora_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">DecoderTransformer</span><span class="p">,</span>
    <span class="n">r</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="p">):</span>
    <span class="c1"># Freeze all layers of the model
</span>    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
        <span class="n">parameter</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="c1"># Replace target modules with LoRALayers
</span>    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
        <span class="n">layer_name</span> <span class="o">=</span> <span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="n">target_modules</span><span class="p">:</span>
            <span class="n">parent_layer_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">parent_module</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">get_submodule</span><span class="p">(</span><span class="n">parent_layer_name</span><span class="p">)</span>

            <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">lora_layer</span> <span class="o">=</span> <span class="nc">LoRALayer</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
                <span class="nf">setattr</span><span class="p">(</span><span class="n">parent_module</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">lora_layer</span><span class="p">)</span>

    <span class="c1"># Unfreeze only the LoRA weights for training
</span>    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="sh">"</span><span class="s">lora_</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div> <p>After fine-tuning is complete, the <code class="language-plaintext highlighter-rouge">merge_and_unload</code> function iterates through the model again, calling the <code class="language-plaintext highlighter-rouge">.merge()</code> method on each <code class="language-plaintext highlighter-rouge">LoRALayer</code> to add the learned update to the original weights. It then replaces the <code class="language-plaintext highlighter-rouge">LoRALayer</code> module with the now-updated, standard <code class="language-plaintext highlighter-rouge">nn.Linear</code> layer, reverting the model to its original architecture, without any <code class="language-plaintext highlighter-rouge">LoRALayer</code> modules.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">merge_and_unload</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">DecoderTransformer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DecoderTransformer</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LoRALayer</span><span class="p">):</span>
            <span class="n">module</span><span class="p">.</span><span class="nf">merge</span><span class="p">()</span>
            
            <span class="n">parent_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">parent_module</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">get_submodule</span><span class="p">(</span><span class="n">parent_name</span><span class="p">)</span>
            <span class="n">layer_name</span> <span class="o">=</span> <span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            
            <span class="nf">setattr</span><span class="p">(</span><span class="n">parent_module</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">module</span><span class="p">.</span><span class="n">W</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div> <p>Visit this <a href="https://colab.research.google.com/drive/1FipCfI8-MPYc3CyDS1-_q9oGOok-g3tS?usp=sharing" rel="external nofollow noopener" target="_blank">Google Collab notebook</a> for a working example with LoRA.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-08-16-peft.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 João A. Leite. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-parameter-efficient-fine-tuning-with-lora",title:"Parameter-Efficient Fine-Tuning with LoRA",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/peft/"}},{id:"post-transformers",title:"Transformers",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/transformers/"}},{id:"news-my-aacl-paper-quot-toxic-language-detection-in-social-media-for-brazilian-portuguese-new-dataset-and-multilingual-analysis-quot-https-aclanthology-org-2020-aacl-main-91-was-awarded-best-undergraduate-paper-by-the-computer-science-department-at-universidade-federal-de-s\xe3o-carlos",title:"My AACL paper [&quot;Toxic language detection in social media for Brazilian Portuguese: New...",description:"",section:"News"},{id:"news-i-started-my-phd-in-computer-science-at-the-university-of-sheffield-sponsored-by-an-epsrc-doctoral-training-partnership-dtp-scholarship",title:"I started my PhD in Computer Science at the University of Sheffield sponsored...",description:"",section:"News"},{id:"news-presenting-my-paper-quot-noisy-self-training-with-data-augmentations-for-offensive-and-hate-speech-detection-tasks-quot-https-aclanthology-org-2023-ranlp-1-68-at-ranlp-2023-in-varna-bulgaria",title:"Presenting my paper [&quot;Noisy Self-Training with Data Augmentations for Offensive and Hate Speech...",description:"",section:"News"},{id:"news-i-was-hired-as-a-part-time-research-associate-in-nlp-and-machine-learning-at-the-university-of-sheffield",title:"I was hired as a part-time Research Associate in NLP and Machine Learning...",description:"",section:"News"},{id:"news-attending-the-lisbon-machine-learning-school-lxmls-http-lxmls-it-pt-2024-sponsored-by-a-google-and-zendesk-scholarship",title:"Attending the Lisbon Machine Learning School ([LxMLS](http://lxmls.it.pt/2024/)) sponsored by a Google and ZenDesk...",description:"",section:"News"},{id:"news-my-paper-quot-euvsdisinfo-a-dataset-for-multilingual-detection-of-pro-kremlin-disinformation-in-news-articles-https-dl-acm-org-doi-abs-10-1145-3627673-3679167-quot-has-been-accepted-for-presentation-at-cikm-2024-in-boise-usa",title:"My paper &quot;[EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News...",description:"",section:"News"},{id:"news-my-paper-quot-a-cross-domain-study-of-the-use-of-persuasion-techniques-in-online-disinformation-https-arxiv-org-abs-2412-15098-quot-has-been-accepted-for-presentation-at-www-2025-in-sydney-australia",title:"My paper &quot;[A Cross-Domain Study of the Use of Persuasion Techniques in Online...",description:"",section:"News"},{id:"news-leading-an-in-house-research-hackathon-project-alongside-four-invited-researchers",title:"Leading an in-house research hackathon project alongside four invited researchers.",description:"",section:"News"},{id:"news-my-paper-quot-weakly-supervised-veracity-classification-with-llm-predicted-credibility-signals-https-doi-org-10-1140-epjds-s13688-025-00534-0-quot-has-been-published-in-the-epj-data-science-journal",title:"My paper &quot;[Weakly supervised veracity classification with LLM-predicted credibility signals](https://doi.org/10.1140/epjds/s13688-025-00534-0)&quot; has been published...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6A.%6C%65%69%74%65@%73%68%65%66%66%69%65%6C%64.%61%63.%75%6B","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-3587-853X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=-OhzTN4AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/joaoaleite","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/joao-augusto-leite","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://www.sheffield.ac.uk/cs/people/research-staff/joao-leite","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>